---
title: "Classification from Scratch"
author: "Bizovi Mihai"
date: "July 16, 2018"
output: html_document
---

[Raw Code and unprocessed notes, use for own risk until declared ready]

`https://freakonometrics.hypotheses.org/` has a lot of great content which is theoretically well founded. Carpentier's series on classification from Scratch drew my attention as an excellent way to go back to the basics of well known models and algorithms. Moreover, he provides minimalist R code which gets to the essence and can be improved as an exercise, which will be used for practice.

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(ggthemes)
library(GGally)
```

```{r}
data <- data.frame(
  x1 = c(.4, .55, .65, .9, .1, .35, .5, .15, .2, .85),
  x2 = c(.85, .95, .8, .87, .5, .55, .5, .2, .1, .3),
  y  = c(1, 1, 1, 1, 1, 0, 0, 1, 0, 0)
)

p <- data %>% 
  mutate(y = as.factor(y)) %>%
  ggplot(aes(x1, x2, color = y)) + 
  geom_point(size = 3) + 
  theme_minimal() + 
  labs(x = "First Feature", y = "Second Feature") + 
  guides(color = guide_legend(title = "target")) + 
  scale_color_ptol()
p
```

```{r}
myocarde <- read.table("http://freakonometrics.free.fr/myocarde.csv",
                      head=TRUE, sep=";") %>% 
  mutate(PRONO = as.numeric(PRONO == "SURVIE"))

y = myocarde$PRONO
X = as.matrix(cbind(1,myocarde[,1:7]))
```

* heart rate
* heart index
* stroke index
* diastolic pressure
* plumonary arterial pressure
* ventricular pressure
* lung resistance
* death or survival

```{r, fig.width=9, fig.height=7}
myocarde %>% 
  ggpairs(columns = 1:7, aes(color = as.factor(PRONO))) + 
  theme_tufte()
```

$$Y \lvert X = x \sim \mathcal{B}(p_x)$$, where 
$$p_x = \frac{\exp{x^T\beta}}{1 + \exp{x^T\beta}}$$

$$
\log \frac{\mathbb{P}(Y = 1)}{\mathbb{P}(Y = 0)} = x^T\beta
$$
$$
\log \mathcal{L} = \sum \limits_{i=1}^n y_i \log p_i + (1 - y_i) \log(1 - p_i)
$$

$$p_i = (1 + \exp(-x_i^T \beta))^{-1}$$

```{r}
y <- myocarde$PRONO
X <- cbind(1, as.matrix(myocarde[, 1:7]))

neg_log_lik <- function(coeffs) {
  -sum(-y * log(1 + exp(-(X %*% coeffs))) - (1-y) * log(1 + exp(X %*% coeffs)))
}

beta_init <- lm(PRONO ~ ., data = myocarde)$coefficients

logistic_opt <- optim(par = beta_init, neg_log_lik, hessian = TRUE)
logistic_opt$par
```
```{r}
simu = function(i){
  logistic_opt_i = optim(par = rnorm(8,0,3)*beta_init, 
  neg_log_lik, hessian=TRUE, method = "BFGS", 
  control=list(abstol=1e-9))
  logistic_opt_i$par[2:3]
}
v_beta = t(Vectorize(simu)(1:1000))
plot(v_beta)
par(mfrow=c(1,2))
hist(v_beta[,1],xlab=names(myocarde)[1])
hist(v_beta[,2],xlab=names(myocarde)[2])
```

$$
\beta_{new} = \beta_{old} - \bigg( \frac{\partial^2 \log \mathscr{L}(\beta_{old})}{\partial \beta\partial\beta^T}  \bigg)^{-1} \cdot\frac{\partial \log \mathscr{L}(\beta_{old})}{\partial \beta}
$$

```{r}
library(optimx)
logit = function(mX, vBeta) {
  exp(mX %*% vBeta)/(1+ exp(mX %*% vBeta)) 
}
logLikelihoodLogitStable = function(vBeta, mX, vY) {
  -sum(vY*(mX %*% vBeta - log(1+exp(mX %*% vBeta))) + 
(1-vY)*(-log(1 + exp(mX %*% vBeta)))) 
}
likelihoodScore = function(vBeta, mX, vY) {
  return(t(mX) %*% (logit(mX, vBeta) - vY) )
}
optimLogitLBFGS = optimx(beta_init, logLikelihoodLogitStable, 
method = 'L-BFGS-B', gr = likelihoodScore, 
mX = X, vY = y, hessian=TRUE)

attr(optimLogitLBFGS, "details")[[2]]
```

```{r}
library(numDeriv)
library(MASS)
logit = function(x){1/(1+exp(-x))}
logLik = function(beta, X, y){
 -sum(y*log(logit(X%*%beta)) + 
(1-y)*log(1-logit(X%*%beta)))
}
optim_second = function(beta, num_iter){
  LL = vector()
  for(i in 1:num_iter){
    grad = (t(X)%*%(logit(X%*%beta) - y)) 
    H = hessian(logLik, beta, method = "complex", X = X, y = y)
    beta = beta - ginv(H)%*%grad
    LL[i] = logLik(beta, X, y)
  }
  result = list(beta, H)
return(result)
}

opt0 = optim_second(beta_init, 500)
opt1 = optim_second(beta_init*runif(8),500)

opt0[[1]]; opt1[[1]]
```
Newton (Fisher) Algorithm
$$
\frac{\partial \log \mathscr{L}(\beta_{old})}{\partial \beta} = X^T(y-p_{old})
$$
$$
\frac{\partial^2 \log \mathscr{L}(\beta_{old})}{\partial \beta \partial \beta ^T} = -X^T \Delta_{old} X
$$
```{r}
Y=myocarde$PRONO
X=cbind(1,as.matrix(myocarde[,1:7]))
colnames(X)=c("Inter",names(myocarde[,1:7]))

# if we change the starting point of the algorithm, it's also robust
beta=as.matrix(lm(Y~0+X)$coefficients,ncol=1)

 for(s in 1:9){
   pi=exp(X%*%beta[,s])/(1+exp(X%*%beta[,s]))
   gradient=t(X)%*%(Y-pi)
   omega=matrix(0,nrow(X),nrow(X));diag(omega)=(pi*(1-pi))
   Hessian=-t(X)%*%omega%*%X
   beta=cbind(beta,beta[,s]-solve(Hessian)%*%gradient)}
 
beta[,8:10]
```

Weighted least squares
$$
\beta_{new} = (X^T\Delta_{old}X)^{-1}X^T\Delta_{old}z
$$
$$
z = X\beta_{old} + \Delta_{old}^{-1}(y - p_{old})
$$
$$
\beta_{new} = argmin \big(  (z-X\beta)^{-1}\Delta^{-1}_{old} (z - X\beta) \big)
$$
```{r}
df = myocarde
beta_init = lm(PRONO~.,data=df)$coefficients
X = cbind(1,as.matrix(myocarde[,1:7]))
beta = beta_init
for(s in 1:1000){
p = exp(X %*% beta) / (1+exp(X %*% beta))
omega = diag(nrow(df))
diag(omega) = (p*(1-p))
df$Z = X %*% beta + solve(omega) %*% (df$PRONO - p)
beta = lm(Z~.,data=df[,-8], weights=diag(omega))$coefficients
}

beta; summary( lm(Z~.,data=df[,-8], weights=diag(omega)))
```
```{r}
summary(glm(PRONO~.,data=myocarde,family=binomial(link = "logit")))
```
```{r}
x = c(.4,.55,.65,.9,.1,.35,.5,.15,.2,.85)
y = c(.85,.95,.8,.87,.5,.55,.5,.2,.1,.3)
z = c(1,1,1,1,1,0,0,1,0,0)
df = data.frame(x1=x,x2=y,y=as.factor(z))
reg = glm(y~x1+x2,data=df,family=binomial(link = "logit"))
u = seq(0,1,length=101)
p = function(x,y) predict.glm(reg,newdata=data.frame(x1=x,x2=y),type="response")
v = outer(u,u,p)
image(u,u,v,xlab="Variable 1",ylab="Variable 2",col=clr10,breaks=(0:10)/10)
points(x,y,pch=19,cex=1.5,col="white")
points(x,y,pch=c(1,19)[1+z],cex=1.5)
contour(u,u,v,levels = .5,add=TRUE)
```

## Making better contour plots in ggplot2
`https://www.r-statistics.com/2016/07/using-2d-contour-plots-within-ggplot2-to-visualize-relationships-between-three-variables/`

```{r}
mtcars %>% 
  mutate(quart = cut(x = qsec, breaks = quantile(qsec))) %>%
  ggplot(aes(x = wt, y = hp, color = quart)) + 
  geom_point(size = 4) + 
  scale_color_ptol() + 
  theme_tufte()
```

```{r}
data_loess <- loess(qsec ~ wt * hp, data = mtcars)
# Create a sequence of incrementally increasing (by 0.3 units) values for both wt and hp
xgrid <-  seq(min(mtcars$wt), max(mtcars$wt), 0.3)
ygrid <-  seq(min(mtcars$hp), max(mtcars$hp), 0.3)
# Generate a dataframe with every possible combination of wt and hp
data.fit <-  expand.grid(wt = xgrid, hp = ygrid)
# Feed the dataframe into the loess model and receive a matrix output with estimates of 
# acceleration for each combination of wt and hp
mtrx3d <-  predict(data_loess, newdata = data.fit)
# Abbreviated display of final matrix
mtrx3d[1:4, 1:4]
contour(x = xgrid, y = ygrid, z = mtrx3d, xlab = "Weight (1,000lbs)", ylab = "Horsepower")

```


```{r}
library(reshape2)
# Transform data to long form
mtrx.melt <- melt(mtrx3d, id.vars = c("wt", "hp"), measure.vars = "qsec")
names(mtrx.melt) <- c("wt", "hp", "qsec")
# Return data to numeric form
mtrx.melt$wt <- as.numeric(str_sub(mtrx.melt$wt, str_locate(mtrx.melt$wt, "=")[1,1] + 1))
mtrx.melt$hp <- as.numeric(str_sub(mtrx.melt$hp, str_locate(mtrx.melt$hp, "=")[1,1] + 1))

head(mtrx.melt)
plot1 <- ggplot(mtrx.melt, aes(x = wt, y = hp, z = qsec)) +
         stat_contour()

# Create ten segments to be colored in
mtrx.melt$equalSpace <- cut(mtrx.melt$qsec, 10)
# Sort the segments in ascending order
breaks <- levels(unique(mtrx.melt$equalSpace))
# Plot
plot3 <- ggplot() +
         geom_tile(data = mtrx.melt, aes(wt, hp, qsec, fill = equalSpace)) +
         geom_contour(color = "white", alpha = 0.5) +
         theme_bw() +
         xlab("Weight (1,000lbs)") +
         ylab("Horsepower") +
         scale_fill_manual(values = c("#35978f", "#80cdc1", "#c7eae5", "#f5f5f5", 
                                     "#f6e8c3", "#dfc27d", "#bf812d", "#8c510a",
                                     "#543005", "#330000"),
                           name = "¼ Mi. Time (s)", breaks = breaks, labels = breaks)

plot4 <- ggplot()  +
         theme_bw() +
         xlab("Weight (1,000lbs)") +
         ylab("Horspower") +
         stat_contour(data = mtrx.melt, aes(x = wt, y = hp, z = qsec, colour = ..level..), 
                     breaks = round(quantile(mtrx.melt$qsec, seq(0, 1, 0.1)), 0), size = 1) +
         scale_color_continuous(name = "¼ Mi. Time (s)") +
         theme(legend.justification=c(1, 0), legend.position=c(1, 0))

plot5 <- plot4 +  
         geom_point(data = mtcars, aes(x = wt, y = hp), shape = 1, size = 2.5, color = "red")
plot6 <- direct.label(plot5, "bottom.pieces")




```































